#!/usr/bin/env python3

"""Hacker News command-line utility.

Interactively select articles to open from top N Hacker News articles (sorted
by points).
"""

import argparse
from collections import namedtuple
import os
import subprocess as sp
import sys
from typing import List

import bs4
from loguru import logger as log
import requests

import gutils


@gutils.catch
def main(argv: List[str] = None) -> None:
    if argv is None:
        argv = sys.argv

    args = parse_cli_args(argv)

    gutils.logging.configure(__file__, debug=args.debug, verbose=args.verbose)

    storylinks: List[bs4.element.Tag] = []
    scores: List[bs4.element.Tag] = []
    for page in range(1, args.pages + 1):
        html = requests.get(f"https://news.ycombinator.com/news?p={page}").text
        soup = bs4.BeautifulSoup(html, "html.parser")

        votearrows = soup.find_all(attrs={"class": "votearrow"})
        page_storylinks = [
            v.find_next(attrs={"class": "storylink"}) for v in votearrows
        ]
        page_scores = [
            v.find_next(attrs={"class": "score"}) for v in votearrows
        ]

        if not 20 <= len(page_storylinks) <= 40:
            raise RuntimeError(
                "Each Hacker News page should include ~30 stories. "
                f"{len(page_storylinks)} !~ 30 on page #{page}."
            )

        if len(page_storylinks) != len(page_scores):
            raise RuntimeError(
                "There should be an equal number of storylinks and scores on "
                f"each page. {len(page_storylinks)} != {len(page_scores)} "
                f"on page #{page}."
            )

        storylinks.extend(page_storylinks)
        scores.extend(page_scores)

    Story = namedtuple("Story", "link score")
    top_N_stories = sorted(
        [Story(link=A[0], score=A[1]) for A in zip(storylinks, scores)],
        key=lambda x: -int(x.score.text.split()[0]),
    )[:args.N]; log.trace(f"top_N_stories = {top_N_stories}")

    keep_alive = True
    while keep_alive:
        os.system("clear")

        # TODO(bugyi): Read list of user-specified keywords from a file and
        # highlight those keywords (using a unique color for each keyword) in
        # the option menu.
        for i, article in enumerate(top_N_stories):
            print(f"[{i+1}]: {article.link.text} ({article.score.text})")

        choices = input("\n>>> ")

        urls = []
        for choice in choices.split():
            if choice == "q":
                keep_alive = False
                continue

            index = int(choice) - 1
            urls.append(top_N_stories[index].link.attrs["href"])

        # TODO(bugyi):
        #   * Open up Hacker News comment page that corresponds with
        #     the story link.
        #   * Upvote selected stories.
        if urls:
            sp.check_call(
                [os.getenv("BROWSER", "qutebrowser"), *urls],
                stdout=sp.DEVNULL,
                stderr=sp.DEVNULL,
            )


def parse_cli_args(argv: List[str]) -> argparse.Namespace:
    parser = gutils.ArgumentParser()

    default = 15
    parser.add_argument(
        "-n",
        "--articles",
        dest="N",
        default=default,
        type=int,
        help="The number of Hacker News articles to show. Defaults to "
             f"{default}.",
    )

    default = 3
    parser.add_argument(
        "-p",
        "--pages",
        type=int,
        default=default,
        help="The number of Hacker News pages to scrape. Defaults to "
             f"{default}.",
    )

    return parser.parse_args(argv[1:])


if __name__ == "__main__":
    main()
